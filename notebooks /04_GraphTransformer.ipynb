{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdS0jmMSZyev"
      },
      "source": [
        "## Transformer GNN Training Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhIQ8EmYZ0UV"
      },
      "source": [
        "###  Drive Mount & Installation\n",
        "\n",
        "We mount Google Drive to access the data and install the required **PyTorch Geometric** libraries for our Transformer GNN implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa5hmND6Yxm4",
        "outputId": "250d21a3-0b0d-4906-edec-cf733b26689e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.5.0+cu121.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3xeuiglZ4XK"
      },
      "source": [
        "### Graph Transformer Configuration\n",
        "\n",
        "This cell defines the hyperparameters specifically tuned for our **Graph Transformer** architecture.\n",
        "\n",
        "**Key Differences from previous models:**\n",
        "* **`HEADS = 4`**: We use Multi-Head Attention to allow the model to focus on different parts of the neighborhood simultaneously.\n",
        "* **`EDGE_DIM = 4`**: Crucial for this architecture, we explicitly define the dimension of edge features (relative position + distance) which drive the attention mechanism.\n",
        "* **`HIDDEN_CHANNELS = 128`**: Transformers generally require wider layers to be effective compared to simple GCNs.\n",
        "* **`NUM_EPOCHS = 100`**: Attention mechanisms typically require more training steps to converge to a stable solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M__GNxNZ5XW",
        "outputId": "9f58c5c9-e704-4607-94c5-a9d115ddc0e1"
      },
      "outputs": [],
      "source": [
        "%%writefile config.py\n",
        "import torch\n",
        "\n",
        "class Config:\n",
        "    \"\"\"\n",
        "    Configuration for the Graph Transformer experiment.\n",
        "    \"\"\"\n",
        "    \n",
        "    # --- Data Paths ---\n",
        "    TRAIN_DATA_PATH = '/content/gdrive/MyDrive/DataSetML4/data/train_data.pt'\n",
        "    VAL_DATA_PATH = '/content/gdrive/MyDrive/DataSetML4/data/val_data.pt'\n",
        "\n",
        "    # --- Training Settings ---\n",
        "    TRAIN_SUBSET_RATIO = 1      # Use 1.0 for full dataset\n",
        "    BATCH_SIZE = 32             # Reduced batch size due to higher memory usage of Transformers\n",
        "\n",
        "    # --- Graph Transformer Architecture ---\n",
        "    IN_CHANNELS = 12            # Input node features\n",
        "    HIDDEN_CHANNELS = 128       # Larger hidden dimension for better expressivity\n",
        "    OUT_CHANNELS = 1            # Target: Scalar stress value\n",
        "    \n",
        "    # Transformer-specific parameters:\n",
        "    HEADS = 4                   # Number of attention heads (Multi-Head Attention)\n",
        "    CONCAT = True               # Concatenate attention head outputs (vs. averaging)\n",
        "    BETA = True                 # Enable bias in the TransformerConv layer\n",
        "    EDGE_DIM = 4                # Dimension of edge features (relative pos + distance)\n",
        "    NUM_LAYERS = 5              # Deeper network to capture long-range dependencies\n",
        "\n",
        "    # --- Optimization ---\n",
        "    NUM_EPOCHS = 100            # Increased epochs as Transformers take longer to converge\n",
        "    LEARNING_RATE = 0.0001\n",
        "    WEIGHT_DECAY = 1e-5\n",
        "    GRADIENT_CLIP = 1.0\n",
        "\n",
        "    # --- Saving ---\n",
        "    BEST_MODEL_PATH = 'best_model.pt'\n",
        "    TRAINING_CURVE_PATH = 'training_curve.png'\n",
        "\n",
        "    # --- Hardware ---\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLGIGlSCZ6Jn"
      },
      "source": [
        "###  Data Loading Compatibility\n",
        "\n",
        "Although the dataset is already normalized, the saved `.pt` files contain instances of `UnitGaussianNormalizer`. We explicitly define this class here to ensure `torch.load` can deserialize the data correctly without raising `AttributeError` or warnings.Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cg2lB7KZ8__",
        "outputId": "c81597de-da3c-40e8-c718-21fcd2276a60"
      },
      "outputs": [],
      "source": [
        "%%writefile utils.py\n",
        "import torch\n",
        "\n",
        "class UnitGaussianNormalizer:\n",
        "    \"\"\"\n",
        "    Applies Unit Gaussian Normalization (Z-score standardization) to tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x=None, eps=1e-5):\n",
        "        \"\"\"\n",
        "        Calculates and stores the mean and standard deviation of the input data 'x'.\n",
        "        \"\"\"\n",
        "        self.eps = eps\n",
        "        if x is not None:\n",
        "            # Calculate statistics across the 0-th dimension (samples)\n",
        "            self.mean = x.mean(dim=0, keepdim=True)\n",
        "            self.std = x.std(dim=0, keepdim=True) + eps\n",
        "        else:\n",
        "            self.mean = None\n",
        "            self.std = None\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"\n",
        "        Normalizes the input x (subtract mean, divide by std).\n",
        "        \"\"\"\n",
        "        if self.mean is None:\n",
        "            return x\n",
        "        return (x - self.mean) / self.std\n",
        "\n",
        "    def decode(self, x, sample_idx=None):\n",
        "        \"\"\"\n",
        "        Un-normalizes x (multiply by std, add mean) to recover original units.\n",
        "        \"\"\"\n",
        "        if self.mean is None:\n",
        "            return x\n",
        "        return x * self.std + self.mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNm5tYllZ-el"
      },
      "source": [
        "### Model Definition: Graph Transformer\n",
        "\n",
        "This cell defines our custom `StressTransformer` architecture. Unlike the U-Net which relies on pooling, this model uses **`TransformerConv`** layers.\n",
        "\n",
        "**Key Architectural Features:**\n",
        "1.  **Edge-Conditioned Attention:** The `edge_dim` parameter allows the model to use the geometric edge features (distances, relative vectors) to calculate attention scores. This means the model learns to \"pay attention\" to nodes based on their physical spatial relationship, not just their connectivity.\n",
        "2.  **Layer Normalization & GELU:** We use standard Transformer components (`LayerNorm`, `GELU`) which stabilize training for deeper networks.\n",
        "3.  **Multi-Head Aggregation:** The input and hidden layers concatenate multiple attention heads to capture diverse features, while the final layer averages them (`concat=False`) to produce the single stress scalar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiP8xWE9aBYp",
        "outputId": "84f91ac4-007b-4a17-e445-8bf77bc29a3d"
      },
      "outputs": [],
      "source": [
        "%%writefile model.py\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import TransformerConv, LayerNorm\n",
        "\n",
        "\n",
        "class StressTransformer(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Transformer Network for Stress Prediction.\n",
        "    Uses Multi-Head Attention to capture long-range dependencies and geometric relationships.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layers = config.NUM_LAYERS\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.norms = torch.nn.ModuleList()\n",
        "\n",
        "        # --- Input Layer ---\n",
        "        # Projects input features to hidden dimension.\n",
        "        # Note: When concat=True, the output dimension is heads * out_channels.\n",
        "        # So we divide config.HIDDEN_CHANNELS by config.HEADS to keep the total width constant.\n",
        "        self.convs.append(TransformerConv(\n",
        "            in_channels=config.IN_CHANNELS,\n",
        "            out_channels=config.HIDDEN_CHANNELS // config.HEADS,\n",
        "            heads=config.HEADS,\n",
        "            concat=config.CONCAT,\n",
        "            beta=config.BETA,\n",
        "            edge_dim=config.EDGE_DIM # Crucial: Incorporates edge features (distance/relative pos) into attention\n",
        "        ))\n",
        "        self.norms.append(LayerNorm(config.HIDDEN_CHANNELS))\n",
        "\n",
        "\n",
        "        # --- Hidden Layers ---\n",
        "        # Stack of Transformer blocks\n",
        "        for _ in range(config.NUM_LAYERS - 2):\n",
        "          self.convs.append(TransformerConv(\n",
        "            in_channels=config.HIDDEN_CHANNELS,\n",
        "            out_channels=config.HIDDEN_CHANNELS // config.HEADS,\n",
        "            heads=config.HEADS,\n",
        "            concat=config.CONCAT,\n",
        "            beta=config.BETA,\n",
        "            edge_dim=config.EDGE_DIM\n",
        "          ))\n",
        "          self.norms.append(LayerNorm(config.HIDDEN_CHANNELS))\n",
        "\n",
        "\n",
        "        # --- Output Layer ---\n",
        "        # Projects back to scalar stress value.\n",
        "        # We set concat=False to average the heads and get a single output per node.\n",
        "        self.out_conv = TransformerConv(\n",
        "            in_channels=config.HIDDEN_CHANNELS,\n",
        "            out_channels=config.OUT_CHANNELS,      # Output size: 1 (Von Mises Stress)\n",
        "            heads=config.HEADS,\n",
        "            concat=False,       # Average the attention heads instead of concatenating\n",
        "            edge_dim=config.EDGE_DIM,\n",
        "            beta=config.BETA,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "      \"\"\"\n",
        "      Forward pass.\n",
        "      Args:\n",
        "          x: Node features [Num_Nodes, In_Channels]\n",
        "          edge_index: Graph connectivity [2, Num_Edges]\n",
        "          edge_attr: Edge features [Num_Edges, Edge_Dim] (Distances, vectors)\n",
        "      \"\"\"\n",
        "      # Pass through hidden layers with Residuals, Norm, and Activation\n",
        "      for i in range(self.num_layers - 1):\n",
        "        x = self.convs[i](x, edge_index, edge_attr)\n",
        "        x = self.norms[i](x)\n",
        "        x = F.gelu(x) # GELU is standard for Transformers (smoother than ReLU)\n",
        "\n",
        "      # Final prediction layer (No activation for regression)\n",
        "      x = self.out_conv(x, edge_index, edge_attr)\n",
        "\n",
        "      return x\n",
        "\n",
        "\n",
        "def create_model(config):\n",
        "    \"\"\"\n",
        "    Factory function to instantiate the StressTransformer.\n",
        "    \"\"\"\n",
        "    model = StressTransformer(config)\n",
        "    model = model.to(config.DEVICE)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoPbwAUDaE7k"
      },
      "source": [
        "### Data Loading & Deserialization\n",
        "\n",
        "This cell generates `data_loading.py`. The provided dataset is stored in a highly optimized \"Collate\" format (concatenated tensors + slice indices) rather than a simple list of objects.\n",
        "\n",
        "Key implementation details:\n",
        "1.  **Module Patching:** We manually inject `UnitGaussianNormalizer` into `sys.modules`. This is a necessary hack to fix a serialization issue where `torch.load` fails to find the custom class definition used when the dataset was originally saved.\n",
        "2.  **Reconstruction:** The `get_graph_from_tuple` function slices the massive concatenated tensors back into individual `Data` objects.\n",
        "3.  **`weights_only=False`**: We explicitly allow pickling of complex objects to support the custom normalizer class embedded in the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjUIXF_aaGKO",
        "outputId": "a2f10a9a-e356-411c-80b2-38a2016d4273"
      },
      "outputs": [],
      "source": [
        "%%writefile data_loading.py\n",
        "import torch\n",
        "import sys\n",
        "import types\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from utils import UnitGaussianNormalizer\n",
        "\n",
        "# --- CRITICAL WORKAROUND ---\n",
        "# The dataset was pickled with a reference to 'utils.UnitGaussianNormalizer'.\n",
        "# To prevent an AttributeError during torch.load, we manually inject this class\n",
        "# into sys.modules so the unpickler can find the definition.\n",
        "sys.modules['utils'] = types.ModuleType('utils')\n",
        "sys.modules['utils'].UnitGaussianNormalizer = UnitGaussianNormalizer\n",
        "\n",
        "def get_graph_from_tuple(data, slices, idx):\n",
        "    \"\"\"\n",
        "    Reconstructs a single Data object from the concatenated storage format.\n",
        "\n",
        "    Args:\n",
        "        data: The monolithic object containing features for all graphs.\n",
        "        slices: Dictionary defining the start/end indices for each graph's features.\n",
        "        idx: Index of the graph to retrieve.\n",
        "    \"\"\"\n",
        "    data_dict = {}\n",
        "    for key in slices.keys():\n",
        "        start, end = slices[key][idx].item(), slices[key][idx + 1].item()\n",
        "\n",
        "        # Handle 2D tensors (like edge_index and face) differently\n",
        "        if key in ['edge_index', 'face'] and data[key].dim() == 2:\n",
        "            data_dict[key] = data[key][:, start:end]\n",
        "        else:\n",
        "            data_dict[key] = data[key][start:end]\n",
        "    return Data(**data_dict)\n",
        "\n",
        "def load_data(config):\n",
        "    \"\"\"\n",
        "    Loads training and validation data, reconstructs graph objects, and creates DataLoaders.\n",
        "    \"\"\"\n",
        "    print(\"Loading data...\")\n",
        "\n",
        "    # Load Train Data\n",
        "    # weights_only=False is required to load custom objects (Normalizer) safely in this context\n",
        "    train_dataset_tuple = torch.load(config.TRAIN_DATA_PATH, weights_only=False)\n",
        "    train_data, train_slices = train_dataset_tuple\n",
        "\n",
        "    # --- Subset Logic ---\n",
        "    # Reduces dataset size based on TRAIN_SUBSET_RATIO (useful for quick tests)\n",
        "    num_graphs = train_slices['x'].size(0) - 1\n",
        "    keep = int(num_graphs * config.TRAIN_SUBSET_RATIO)\n",
        "\n",
        "    new_slices = {}\n",
        "    for key in train_slices.keys():\n",
        "        new_slices[key] = train_slices[key][:keep+1].clone()\n",
        "    train_slices = new_slices\n",
        "\n",
        "    # Load Validation Data\n",
        "    test_dataset_tuple = torch.load(config.VAL_DATA_PATH, weights_only=False)\n",
        "    test_data, test_slices = test_dataset_tuple\n",
        "\n",
        "    # Reconstruct individual graph objects from the storage tensors\n",
        "    # This loop converts the efficient storage format back into a list of Data objects\n",
        "    train_graphs = [get_graph_from_tuple(train_data, train_slices, i)\n",
        "                    for i in range(train_slices['x'].size(0) - 1)]\n",
        "    val_graphs = [get_graph_from_tuple(test_data, test_slices, i)\n",
        "                  for i in range(test_slices['x'].size(0) - 1)]\n",
        "\n",
        "    # Create PyTorch Geometric DataLoaders\n",
        "    # These handle the dynamic batching of graphs (diagonal adjacency stacking)\n",
        "    train_loader = DataLoader(train_graphs, batch_size=config.BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_graphs, batch_size=config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, len(train_graphs), len(val_graphs), train_graphs, val_graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21humdTIaISk"
      },
      "source": [
        "### Dynamic Training Loop with Geometric Features\n",
        "\n",
        "This cell generates `training.py`.\n",
        "\n",
        "**Important Difference for Transformers:**\n",
        "Unlike standard GNNs, the Transformer architecture requires explicit geometric edge features (`edge_attr`) to compute attention scores.\n",
        "* **On-the-fly computation:** Inside `train_epoch` and `validate`, we dynamically calculate the **relative position vectors** and **Euclidean distances** between connected nodes.\n",
        "* **Input:** These features are concatenated and passed to the `model` forward pass alongside node features (`batch.x`) and connectivity (`batch.edge_index`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dknm0K4KaJmb",
        "outputId": "c6472e72-a9c6-4c64-a02c-d862279ece5c"
      },
      "outputs": [],
      "source": [
        "%%writefile training.py\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, device, gradient_clip, num_train_graphs):\n",
        "    \"\"\"\n",
        "    Performs one training epoch for the Transformer.\n",
        "    Crucial: Computes edge features (relative pos + distance) on the fly.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # --- Dynamic Edge Feature Computation ---\n",
        "        # The Transformer needs geometric info on edges.\n",
        "        # We calculate relative positions and Euclidean distances between connected nodes.\n",
        "        src, dst = batch.edge_index\n",
        "        rel_pos = batch.pos[src] - batch.pos[dst]            # Relative position vector (dx, dy, dz)\n",
        "        dist = torch.norm(rel_pos, dim=1, keepdim=True)      # Euclidean distance (scalar)\n",
        "        edge_attr = torch.cat([rel_pos, dist], dim=1)        # Concatenate -> [Edges, 4]\n",
        "\n",
        "        # Forward pass with edge attributes\n",
        "        out = model(batch.x, batch.edge_index, edge_attr)\n",
        "\n",
        "        loss = F.huber_loss(out.view(-1), batch.y.view(-1), delta=0.5)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=gradient_clip)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    return train_loss / num_train_graphs\n",
        "\n",
        "def validate(model, val_loader, device, num_val_graphs):\n",
        "    \"\"\"\n",
        "    Evaluates the Transformer model.\n",
        "    Computes edge features dynamically for validation graphs.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    all_preds_global = []\n",
        "    all_targets_global = []\n",
        "    graph_scores_with_indices = []\n",
        "    global_idx_offset = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "\n",
        "            # --- Dynamic Edge Feature Computation (Same as training) ---\n",
        "            src, dst = batch.edge_index\n",
        "            rel_pos = batch.pos[src] - batch.pos[dst]\n",
        "            dist = torch.norm(rel_pos, dim=1, keepdim=True)\n",
        "            edge_attr = torch.cat([rel_pos, dist], dim=1)\n",
        "\n",
        "            out = model(batch.x, batch.edge_index, edge_attr)\n",
        "\n",
        "            loss = F.huber_loss(out.view(-1), batch.y.view(-1), delta=0.5)\n",
        "            val_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "            preds_cpu = out.view(-1).cpu().numpy()\n",
        "            targets_cpu = batch.y.view(-1).cpu().numpy()\n",
        "            batch_indices = batch.batch.cpu().numpy()\n",
        "\n",
        "            all_preds_global.append(preds_cpu)\n",
        "            all_targets_global.append(targets_cpu)\n",
        "\n",
        "            # R2 Calculation per graph\n",
        "            unique_graphs = np.unique(batch_indices)\n",
        "            for graph_id in unique_graphs:\n",
        "                mask = (batch_indices == graph_id)\n",
        "                graph_targets = targets_cpu[mask]\n",
        "                graph_preds = preds_cpu[mask]\n",
        "\n",
        "                if len(graph_targets) > 1:\n",
        "                    score = r2_score(graph_targets, graph_preds)\n",
        "                    real_global_index = global_idx_offset + graph_id\n",
        "                    graph_scores_with_indices.append((real_global_index, score))\n",
        "\n",
        "            global_idx_offset += batch.num_graphs\n",
        "\n",
        "    val_loss /= num_val_graphs\n",
        "\n",
        "    metrics = {}\n",
        "    selected_indices = [None, None, None]\n",
        "\n",
        "    if len(all_preds_global) > 0:\n",
        "        final_preds = np.concatenate(all_preds_global)\n",
        "        final_targets = np.concatenate(all_targets_global)\n",
        "\n",
        "        metrics['RMSE'] = np.sqrt(mean_squared_error(final_targets, final_preds))\n",
        "        metrics['MAE'] = mean_absolute_error(final_targets, final_preds)\n",
        "\n",
        "        if len(graph_scores_with_indices) > 0:\n",
        "            indices_arr = np.array([item[0] for item in graph_scores_with_indices])\n",
        "            scores_arr = np.array([item[1] for item in graph_scores_with_indices])\n",
        "\n",
        "            metrics['R2_90PCT'] = np.percentile(scores_arr, 90)\n",
        "            metrics['R2_50PCT'] = np.percentile(scores_arr, 50)\n",
        "            metrics['R2_10PCT'] = np.percentile(scores_arr, 10)\n",
        "\n",
        "            idx_best = indices_arr[np.argmax(scores_arr)]\n",
        "            idx_worst = indices_arr[np.argmin(scores_arr)]\n",
        "            mean_score = np.mean(scores_arr)\n",
        "            idx_closest_to_mean = indices_arr[(np.abs(scores_arr - mean_score)).argmin()]\n",
        "\n",
        "            selected_indices = [int(idx_best), int(idx_closest_to_mean), int(idx_worst)]\n",
        "        else:\n",
        "            metrics['R2_90PCT'] = 0; metrics['R2_50PCT'] = 0; metrics['R2_10PCT'] = 0\n",
        "\n",
        "    return val_loss, metrics, selected_indices\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, config, num_train_graphs, num_val_graphs):\n",
        "    print(f\"Starting training on {config.DEVICE}...\")\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'RMSE': [], 'MAE': [],\n",
        "        'R2_90PCT': [], 'R2_50PCT': [], 'R2_10PCT': []\n",
        "    }\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(1, config.NUM_EPOCHS + 1):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, config.DEVICE, config.GRADIENT_CLIP, num_train_graphs)\n",
        "        val_loss, metrics, index = validate(model, val_loader, config.DEVICE, num_val_graphs)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['RMSE'].append(metrics['RMSE'])\n",
        "        history['MAE'].append(metrics['MAE'])\n",
        "        history['R2_90PCT'].append(metrics['R2_90PCT'])\n",
        "        history['R2_50PCT'].append(metrics['R2_50PCT'])\n",
        "        history['R2_10PCT'].append(metrics['R2_10PCT'])\n",
        "\n",
        "        print(f\"Ep {epoch:03d} | Val: {val_loss:.4f} | RMSE: {metrics['RMSE']:.3f} | \"\n",
        "              f\"R2(10/50/90): {metrics['R2_10PCT']:.2f} / {metrics['R2_50PCT']:.2f} / {metrics['R2_90PCT']:.2f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), config.BEST_MODEL_PATH)\n",
        "\n",
        "    return history, best_val_loss, index\n",
        "\n",
        "def plot_metrics(history, save_path):\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(10, 15), sharex=True)\n",
        "\n",
        "    axs[0].plot(epochs, history['train_loss'], label=\"Train Loss\", color='blue')\n",
        "    axs[0].plot(epochs, history['val_loss'], label=\"Val Loss\", color='red')\n",
        "    axs[0].set_ylabel(\"Huber Loss\")\n",
        "    axs[0].set_title(\"Training & Validation Loss\")\n",
        "    axs[0].legend(); axs[0].grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    axs[1].plot(epochs, history['RMSE'], label=\"RMSE\", color='orange')\n",
        "    axs[1].plot(epochs, history['MAE'], label=\"MAE\", color='green')\n",
        "    axs[1].set_ylabel(\"Error Units\")\n",
        "    axs[1].set_title(\"Global Error Metrics\")\n",
        "    axs[1].legend(); axs[1].grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    axs[2].plot(epochs, history['R2_90PCT'], label=\"R2 Best (90%)\", linestyle='--', color='purple')\n",
        "    axs[2].plot(epochs, history['R2_50PCT'], label=\"R2 Median (50%)\", linewidth=2, color='black')\n",
        "    axs[2].plot(epochs, history['R2_10PCT'], label=\"R2 Worst (10%)\", linestyle=':', color='brown')\n",
        "    axs[2].axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
        "    axs[2].set_ylabel(\"R2 Score\")\n",
        "    axs[2].set_xlabel(\"Epochs\")\n",
        "    axs[2].set_title(\"R2 Score Distribution (Per Geometry)\")\n",
        "    axs[2].legend(loc='lower right'); axs[2].grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    print(f\"Learning curves saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y89BfTtaL59"
      },
      "source": [
        "### Main Execution: Graph Transformer\n",
        "\n",
        "This cell generates `main.py`. It serves as the central entry point that integrates:\n",
        "1.  The **Transformer Configuration** (defining heads, layers, etc.).\n",
        "2.  The **`StressTransformer` model**.\n",
        "3.  The **Dynamic Training Loop** (which handles edge feature computation).\n",
        "\n",
        "When executed, it trains the model, saves the performance history, and identifies the best/worst test cases for the final visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpkrFPstaMlj",
        "outputId": "d952eba3-43b5-4ed2-f144-d44d1ec23d9f"
      },
      "outputs": [],
      "source": [
        "%%writefile main.py\n",
        "import torch\n",
        "from config import Config\n",
        "from data_loading import load_data\n",
        "from model import create_model\n",
        "from training import train_model, plot_metrics\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Orchestrates the Graph Transformer training pipeline.\n",
        "    Connects the configuration, data loader, custom Transformer model,\n",
        "    and the training loop.\n",
        "    \"\"\"\n",
        "    # 1. Initialize Transformer-specific configuration\n",
        "    config = Config()\n",
        "\n",
        "    # 2. Load Data\n",
        "    # Returns loaders and raw graph lists (needed for visualization later)\n",
        "    train_loader, val_loader, num_train, num_val, train_graph, val_graph = load_data(config)\n",
        "\n",
        "    # 3. Build the Graph Transformer Model\n",
        "    # Uses the hyperparameters (Heads, Layers, Edge Dim) defined in Config\n",
        "    model = create_model(config)\n",
        "\n",
        "    # 4. Setup Optimizer\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=config.LEARNING_RATE,\n",
        "        weight_decay=config.WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "    # 5. Execute Training\n",
        "    # The 'train_model' function handles the epoch loop and the dynamic\n",
        "    # computation of edge features required by the Transformer.\n",
        "    history, best_val_loss, index = train_model(\n",
        "        model, train_loader, val_loader, optimizer, config, num_train, num_val\n",
        "    )\n",
        "\n",
        "    # 6. Save Learning Curves\n",
        "    plot_metrics(history, config.TRAINING_CURVE_PATH)\n",
        "\n",
        "    # Return trained model and validation samples for the 3D visualization step\n",
        "    return model, index, val_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execution\n",
        "\n",
        "This cell runs the entire pipeline defined in `main.py`. It trains the model, plots the learning curves, and returns the best/worst case indices needed for the qualitative analysis in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xW8wRPuEq6FX",
        "outputId": "761b92e1-970a-4e40-f1c4-eb0e7c1bf13e"
      },
      "outputs": [],
      "source": [
        "from main import main\n",
        "\n",
        "\n",
        "model, index, val_graph = main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwUNGdjlpuVS"
      },
      "source": [
        "### Qualitative Analysis: 3D Stress Field Visualization\n",
        "\n",
        "This cell performs the final visual inspection of the model's predictions. We iterate through the specific test cases identified earlier: **Best, Median, and Worst** performance.\n",
        "\n",
        "**Key Feature: Independent Color Scaling**\n",
        "The `visualize_side_by_side_independent` function allows the color map to scale dynamically for each plot:\n",
        "* **Left (Target):** Ground truth from FEM.\n",
        "* **Right (Prediction):** GNN output.\n",
        "\n",
        "**Why independent scales?**\n",
        "This allows us to verify if the model has learned the correct **stress distribution patterns** (topology of the hotspots), even if the absolute **magnitudes** are underestimated (a common issue known as \"over-smoothing\" in regression tasks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ezeHsb9HptyE",
        "outputId": "c4f2e1dc-c9df-4f11-97c2-6035b826fd07"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import torch\n",
        "import numpy as np\n",
        "from config import Config\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "# Import the main module and reload it to ensure latest changes are used\n",
        "import main\n",
        "importlib.reload(main)\n",
        "\n",
        "# --- 1. SIDE-BY-SIDE VISUALIZATION FUNCTION (INDEPENDENT SCALES) ---\n",
        "def visualize_side_by_side_independent(target_data, pred_data, index):\n",
        "    \"\"\"\n",
        "    Displays Ground Truth and Prediction side-by-side.\n",
        "    Uses INDEPENDENT color scales for each plot to visualize stress PATTERNS\n",
        "    effectively, regardless of the difference in absolute magnitude.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check for mesh faces\n",
        "    if not hasattr(target_data, 'face') or target_data.face is None:\n",
        "        print(\"⚠️ No faces detected in mesh data.\")\n",
        "        return\n",
        "\n",
        "    # --- Extract Mesh Data ---\n",
        "    x = target_data.x[:, 0].cpu().numpy()\n",
        "    y = target_data.x[:, 1].cpu().numpy()\n",
        "    z = target_data.x[:, 2].cpu().numpy()\n",
        "    faces = target_data.face.cpu().numpy()\n",
        "    i, j, k = faces[0], faces[1], faces[2]\n",
        "\n",
        "    val_target = target_data.y[:, 0].cpu().numpy()\n",
        "    val_pred = pred_data.y[:, 0].cpu().numpy()\n",
        "\n",
        "    # --- Create Subplots ---\n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=2,\n",
        "        specs=[[{'type': 'scene'}, {'type': 'scene'}]],\n",
        "        subplot_titles=(\n",
        "            f\"GROUND TRUTH (Max: {val_target.max():.2f})\",\n",
        "            f\"PREDICTION (Max: {val_pred.max():.2f})\"\n",
        "        ),\n",
        "        horizontal_spacing=0.05\n",
        "    )\n",
        "\n",
        "    # --- Trace 1: Left (Ground Truth) ---\n",
        "    fig.add_trace(\n",
        "        go.Mesh3d(\n",
        "            x=x, y=y, z=z, i=i, j=j, k=k,\n",
        "            intensity=val_target,\n",
        "            intensitymode='vertex',\n",
        "            colorscale='Jet',\n",
        "            # INDEPENDENT SCALE: Based on TARGET min/max\n",
        "            cmin=val_target.min(),\n",
        "            cmax=val_target.max(),\n",
        "            opacity=1.0,\n",
        "            name='GROUND TRUTH',\n",
        "            colorbar=dict(title=\"Target Stress\", x=0.45, len=0.8)\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # --- Trace 2: Right (Prediction) ---\n",
        "    fig.add_trace(\n",
        "        go.Mesh3d(\n",
        "            x=x, y=y, z=z, i=i, j=j, k=k,\n",
        "            intensity=val_pred,\n",
        "            intensitymode='vertex',\n",
        "            colorscale='Jet',\n",
        "            # INDEPENDENT SCALE: Based on PREDICTION min/max\n",
        "            cmin=val_pred.min(),\n",
        "            cmax=val_pred.max(),\n",
        "            opacity=1.0,\n",
        "            name='PREDICTION',\n",
        "            colorbar=dict(title=\"Pred Stress\", x=1.0, len=0.8) # Second legend bar\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    # --- Layout ---\n",
        "    fig.update_layout(\n",
        "        title_text=f\"Von Mises Stress Comparison - Independent Scales (Mesh #{index})\",\n",
        "        height=600, width=1200,\n",
        "        margin=dict(r=0, b=0, l=0, t=50),\n",
        "        scene=dict(aspectmode='data'),\n",
        "        scene2=dict(aspectmode='data')\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "# --- 2. EXECUTION ---\n",
        "# Specific indices chosen for analysis (Benchmarks and Complex geometries)\n",
        "\n",
        "for i in index:\n",
        "  print(f\"--- Comparison (Decoupled Scales) for Part #{i} ---\")\n",
        "\n",
        "  # Prepare data\n",
        "  target_graph = val_graph[i].clone().to(Config.DEVICE)\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      # --- TRANSFORMER SPECIFIC STEP ---\n",
        "      # We must re-compute edge attributes (Relative Position + Distance)\n",
        "      # because the model expects them in the forward pass.\n",
        "      src, dst = target_graph.edge_index\n",
        "      rel_pos = target_graph.pos[src] - target_graph.pos[dst]\n",
        "      dist = torch.norm(rel_pos, dim=1, keepdim=True)\n",
        "      edge_attr = torch.cat([rel_pos, dist], dim=1)\n",
        "\n",
        "      # Inference\n",
        "      pred_tensor = model(target_graph.x, target_graph.edge_index, edge_attr)\n",
        "\n",
        "  prediction_graph = target_graph.clone()\n",
        "  prediction_graph.y = pred_tensor\n",
        "\n",
        "  # Visualize\n",
        "  visualize_side_by_side_independent(target_graph, prediction_graph, i)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
